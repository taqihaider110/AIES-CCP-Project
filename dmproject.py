# -*- coding: utf-8 -*-
"""DMProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PODJ8084Y0D6QN-XvXtTAwGbd47dn1nB

**IMPORTING RELEVANT LIBRARIES**
"""

import pickle
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

import re # Regular expressions
import nltk
from nltk.corpus import stopwords # Stop words removal
from nltk.tokenize import word_tokenize # Word tokenization
from nltk.stem import WordNetLemmatizer  # Word lemmatization
# Download NLTK resources
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')
nltk.download('wordnet')
# !pip install wordcloud
from wordcloud import WordCloud

from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF vectorization
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.utils import resample, shuffle
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB, BernoulliNB, ComplementNB
from sklearn.svm import SVC
# !pip install xgboost
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
# !pip install scikit-optimize
from skopt import BayesSearchCV

# Loading the dataset
data = pd.read_csv("amazon-updated.csv")

# Checking the shape
data.shape

#Checking the Cloumns
data.columns

# Previewing the dataset
data.head()

# Checking the Scores/Ratings Distribution
data.Score.value_counts()

# Checking for Missing Values
data.isnull().sum()

# Dropping the Rows with Missing Values
data.dropna(inplace=True)

# Checking the shape again
data.shape

# Removing the unnecessary features and retaining the relevant features for Sentiment Analysis
data = data[['Score','Summary','Text']]

# Previewing the dataset again
data.head()

# Making the copy of the dataset
df = data.copy()

# Concatenating the Summary and Text features
df['Review'] = df['Summary'] + " " + df['Text']
df = df.drop(['Summary','Text'],axis=1)
df.head()

# Cleaning the Dataset

def clean_text(text):
    text = re.sub(r'<.*?>', '', text) # Remove HTML tags
    text = re.sub(r'[^\w\s]', '', text) # Remove punctuation
    text = text.lower() # Convert to lowercase
    return text

df['Review'] = df['Review'].apply(clean_text)
df.head()

# Initializing the stop words and lemmatizer
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

# Defining a function to preprocess the text
def preprocess_text(review):
    # Tokenization
    tokens = word_tokenize(review)

    # Stopword Removal
    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]

    # Lemmatization
    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]

     # Join the tokens back into a string
    cleaned_review = ' '.join(lemmatized_tokens)

    return cleaned_review

# Applying the function to the Review column
df['cleaned_review'] = df['Review'].apply(preprocess_text)

df = df.drop(['Review'], axis=1)

# Previewing the data
df.head()

# Combining all cleaned reviews into a single string
text = ' '.join(df['cleaned_review'].astype(str).tolist())

# Creating a WordCloud object
wordcloud = WordCloud(width = 800, height = 800,
                background_color ='white',
                stopwords = stop_words, # Use the stop words you defined earlier
                min_font_size = 10).generate(text)

# Plotting the WordCloud image
plt.figure(figsize = (8, 8), facecolor = None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad = 0)
plt.show()

# Defining sentiment labels based on the rating
def get_sentiment(rating):
    if rating < 3.0:
        return 'negative'
    elif rating >= 4.0:
        return 'positive'
    else:
        return 'neutral'

# Applying the function to create a new sentiment column
df['sentiment'] = df['Score'].apply(get_sentiment)

# Dropping the rating column as it has served its purpose
df = df.drop(['Score'], axis=1)

df.head()

# Checking for class distribution
print(df['sentiment'].value_counts())

# Visualize the distribution
sns.countplot(x='sentiment', data=df)
plt.title('Sentiment Class Distribution')
plt.show()

# Encode the sentiment labels using LabelEncoder
encoder = LabelEncoder()
df['sentiment'] = encoder.fit_transform(df['sentiment'])
df.head()

# Separate the classes
positive_reviews = df[df['sentiment'] == 2]
neutral_reviews = df[df['sentiment'] == 1]
negative_reviews = df[df['sentiment'] == 0]

# Downsample positive reviews
positive_reviews_downsampled = resample(positive_reviews,
                                        replace=False,     # sample without replacement
                                        n_samples=85000,   # match the negative sample size
                                        random_state=42)   # for reproducibility

# Combine downsampled positives with original neutral and negative
balanced_df = pd.concat([positive_reviews_downsampled, neutral_reviews, negative_reviews])

balanced_df.shape

print(balanced_df.value_counts('sentiment'))

# Visualize the distribution
sns.countplot(x='sentiment', data=balanced_df)
plt.title('Sentiment Class Distribution')
plt.show()

# Shuffling the data
balanced_df = shuffle(balanced_df, random_state=42)

# Splitting the dataset into training and testing datasets
X_train, X_test, y_train, y_test = train_test_split(balanced_df['cleaned_review'], balanced_df['sentiment'], stratify=balanced_df['sentiment'], train_size=0.8 , test_size=0.2, random_state=42)

#TF-IDF Vectorization
vect = TfidfVectorizer(max_features=7500, ngram_range=(1, 2), max_df=0.85, min_df=2)
X_train_vectorized = vect.fit_transform(X_train)  # Fit on training data
X_test_vectorized = vect.transform(X_test)        # Transform test data with the same vectorizer

import pickle
# Save the vectorized datasets to a file using pickle
with open('vectorized_data.pkl', 'wb') as file:
    pickle.dump(vect, file)

# Checking the Vocabulary Size
vocab_size = len(vect.vocabulary_)
print("Vocabulary size:", vocab_size)

#SMOTE Upsampling on Training Data
smote = SMOTE(sampling_strategy='not majority', random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_vectorized, y_train)

"""# XGBOOST"""

# Define the parameter space
param_space = {
    'learning_rate': (0.05, 0.2),   # Log scale for smaller increments
    'max_depth': (4, 6),                          # Reasonable range for max depth
    'n_estimators': (100, 300)                     # Number of trees
}
# Initialize the XGBClassifier
xgb = XGBClassifier(objective='multi:softmax', eval_metric='mlogloss', random_state=42)

# Set up the Bayesian Search
bayes_search = BayesSearchCV(
    estimator=xgb,
    search_spaces=param_space,
    n_iter=5,                       # Number of parameter settings that are sampled
    cv=2,                            # Number of cross-validation folds
    scoring='f1_micro',              # Scoring metric for optimization
    n_jobs=-1,                       # Use all available cores
    random_state=42,
    verbose=1
)

# Perform Bayesian optimization
bayes_search.fit(X_train_balanced, y_train_balanced)

# Print the best parameters and model evaluation metrics
print("Best Parameters from Bayesian Optimization:", bayes_search.best_params_)
print("Best CV Score:", bayes_search.best_score_)

# Use the best estimator to predict on test data
best_xgb = bayes_search.best_estimator_
y_pred = best_xgb.predict(X_test_vectorized)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy on Test Set:", accuracy)
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

with open('best_xgb_model.pkl', 'wb') as file:
    pickle.dump(best_xgb, file)

"""# LOGISTIC REGRESSION"""

param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10],
    'penalty': ['l1', 'l2']
}

grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)
grid_search.fit(X_train_balanced, y_train_balanced)

best_params = grid_search.best_params_

best_model = grid_search.best_estimator_

print("Best Hyperparameters:", best_params)
print(best_model)

# Initialize the logistic regression model with L2 regularization (default for 'penalty' is 'l2')
log_reg_model = LogisticRegression(penalty='l2', C=10, solver='lbfgs', max_iter=1000, random_state=42)

# Train the model on the vectorized training data
log_reg_model.fit(X_train_balanced, y_train_balanced)

# Predict on the vectorized test set
y_pred = log_reg_model.predict(X_test_vectorized)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

with open('log_reg_model.pkl', 'wb') as file:
    pickle.dump(log_reg_model, file)

"""MULTINOMIAL NAIVE BAYES
-----------------------
"""

# Define the parameter grid
param_grid = {
    'alpha': [0.1, 0.5, 1.0, 2.0, 5.0],  # Try a range of alpha values
    'fit_prior': [False,True],  # Experiment with fitting priors
    'class_prior': [None, [0.3, 0.7]]  # Explore different class priors

}

# Initialize the Multinomial Naive Bayes model
nb_model = MultinomialNB(random_state=42)

# Set up GridSearchCV with cross-validation
grid_search = GridSearchCV(nb_model, param_grid, cv=5, scoring='f1_micro', n_jobs=-1)
grid_search.fit(X_train_balanced, y_train_balanced)

# Get the best parameters
print("Best Parameters from Grid Search:", grid_search.best_params_)

# Train the model with the best parameters
best_nb_model = grid_search.best_estimator_

# Make predictions on the test set
y_pred = best_nb_model.predict(X_test_vectorized)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

"""# BERNOULLI NAIVE BAYES"""

# Initialize the Bernoulli Naive Bayes model
bernoulli_model = BernoulliNB(random_state=42)

# Set up GridSearchCV with cross-validation
grid_search = GridSearchCV(bernoulli_model, param_grid, cv=5, scoring='f1_micro', n_jobs=-1)
grid_search.fit(X_train_balanced, y_train_balanced)

# Get the best parameters
print("Best Parameters from Grid Search:", grid_search.best_params_)

# Train the model with the best parameters
best_bernoulli_model = grid_search.best_estimator_

# Make predictions on the test set
y_pred = best_bernoulli_model.predict(X_test_vectorized)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

"""# SVM(SUPPORT VECTOR MACHINE"""

svm_model = SVC(kernel='linear', random_state=42)
svm_model.fit(X_train_balanced, y_train_balanced)

y_pred = svm_model.predict(X_test_vectorized)

svm_accuracy = accuracy_score(y_test, y_pred)
print("SVM Model Accuracy:", svm_accuracy)
print("\nClassification Report:\n", classification_report(y_test, y_pred))

with open('SVM.pkl', 'wb') as file:
    pickle.dump(svm_model, file)

"""# DATAFRAME VISUALIZATION (ACCURACY AND LOSS)"""

data = {
    'Model': ['XGBoost', 'Logistic Regression', 'MultiNomial Naive Bayes', 'Bernoulli Naive Bayes', 'SVM'],
    'Accuracy': [0.7628, 0.7899, 0.7270, 0.6544, 0.7884],
    'Loss':[1-0.7628, 1-0.7899, 1-0.7270, 1-0.6544, 1-0.7884]
}
df = pd.DataFrame(data)

# Create a grouped bar chart
x = np.arange(len(df['Model']))  # Position of groups on the x-axis
width = 0.35  # Width of the bars

# Initialize the plot
fig, ax = plt.subplots(figsize=(10, 6))

# Plot bars for Accuracy and Loss
accuracy_bars = ax.bar(x - width/2, df['Accuracy'], width, label='Accuracy', color='skyblue')
loss_bars = ax.bar(x + width/2, df['Loss'], width, label='Loss', color='orange')

# Add labels and title
ax.set_xlabel('Model')
ax.set_ylabel('Value')
ax.set_title('Model Accuracies and Losses')
ax.set_xticks(x)
ax.set_xticklabels(df['Model'])
ax.legend()

# Add value annotations on top of bars
def add_labels(bars):
    for bar in bars:
        height = bar.get_height()
        ax.annotate(f'{height:.2f}',  # Text to display
                    xy=(bar.get_x() + bar.get_width() / 2, height),  # Position
                    xytext=(0, 3),  # Offset
                    textcoords="offset points",
                    ha='center', va='bottom')

add_labels(accuracy_bars)
add_labels(loss_bars)

# Show the plot
plt.tight_layout()
plt.show()

metrics_dict = {
    'Model': ['Logistic Regression', 'XGBoost', 'Multinomial Naive Bayes', 'Bernoulli Naive Bayes', 'SVM'],
    'Accuracy': ['79%', '76%', '73%', '65%', '79%'],
    'Precision': ['80%', '76%', '76%', '67%', '80%'],
    'Recall': ['79%', '76%', '73%', '65%', '79%'],
    'F1-Score': ['79%', '76%', '74%', '65%', '79%'],
    'TrainingTime (mins)': [25, 258, 4, 5, 180]
}

metrics_df = pd.DataFrame(metrics_dict)
metrics_df